import os
import numpy as np
import joblib as jl
from sklearn.metrics import hamming_loss
from sklearn.metrics import zero_one_loss
from sklearn.metrics import f1_score
from skmultilearn.dataset import load_from_arff
import argparse
import pickle as pk

def get_sample_acc(y_pred, y_true):
    right_count = 0
    for i in range(y_true.shape[0]):
        flag = True
        flag2 = False
        for j in range(y_true.shape[1]):
            if y_true[i][j]==0 and y_pred[i][j]==1:
                flag = False
                break
        for j in range(y_true.shape[1]):
            if y_pred[i][j] == 1:
                flag2 = True
                break
        if flag and flag2:
            right_count += 1
    return format(right_count / y_true.shape[0], '.8f')
    
def get_label_avg(y_pred, y_true):
    right_count_list = np.array([0,0,0,0,0,0])
    for i in range(y_true.shape[0]):
        for j in range(y_true.shape[1]):
            if  y_true[i][j] == y_pred[i][j]:
                right_count_list[j] += 1
    label_acc = right_count_list / y_true.shape[0]
    sum = 0
    # print(label_acc) #for dbg
    for l_acc in label_acc:
        sum += l_acc
    return format(sum / y_true.shape[1], '.8f')

if __name__ == '__main__':
    parse = argparse.ArgumentParser()
    parse.add_argument('--model_path', default='./model/base_model/CDN_J48.pkl', type=str,
                       help='load the .pkl file' )
    parse.add_argument('--test_path', default='./test_set/manual_test.arff', type=str,
                       help='path of test set')
    parse.add_argument('--meka_path', default='/home/rtfeng/fei/meka-release-1.9.2/lib/', type=str,
            help='meka path')
    parse.add_argument('--java_path',default='/home/rtfeng/fei/jdk-17.0.1/bin/java', type=str,
            help='java path')
    args = parse.parse_args()
    
    data = pk.load(open(args.model_path, 'rb'))
    changed_data = data
    changed_data.java_command = args.java_path
    changed_data.meka_classpath = args.meka_path
    pk.dump(changed_data, open(args.model_path, 'wb'))

    model = jl.load(args.model_path)
    test_path = args.test_path

    x_test, y_test = load_from_arff(test_path, label_count=6)
    y_pred = model.predict(x_test)
    y_pred = np.array(y_pred.todense())
    y_true = np.array(y_test.todense())
    sample_acc = get_sample_acc(y_pred, y_true)
    hammingloss = hamming_loss(y_true=y_true, y_pred=y_pred)
    hammingloss = format(hammingloss, '.8f')
    oneerror = zero_one_loss(y_true=y_true, y_pred=y_pred)
    oneerror = format(oneerror, '.8f')
    instance_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='samples')
    instance_f1 = format(instance_f1, '.8f')
    L_avg = get_label_avg(y_pred, y_true)
    #L_avg = format(L_avg, '.8f')

    print(f'hamming loss: {hammingloss}')
    print(f'zero-one error: {oneerror}')
    print(f'F1 score: {instance_f1}')
    print(f'sample-ACC: {sample_acc}')
    print(f'Avg. label-ACC: {L_avg}')
